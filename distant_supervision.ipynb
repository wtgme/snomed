{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall scispacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# ! pip install en_core_sci_scibert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "import scispacy\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime \n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "from scispacy.linking import EntityLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k1810895/.conda/envs/py39/lib/python3.9/site-packages/spacy/language.py:813: UserWarning: [W119] Overriding pipe name in `config` is not supported. Ignoring override 'umls'.\n",
      "  warnings.warn(Warnings.W119.format(name_in_config=config.pop(\"name\")))\n",
      "/users/k1810895/.conda/envs/py39/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/users/k1810895/.conda/envs/py39/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"name\": \"umls\"})\n",
    "linker = nlp.get_pipe(\"scispacy_linker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes = pd.read_csv(\"/users/k1810895/data/KER/data/mimic_notes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# for sent in tokens.sents:\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#     print(sent.text, sent.start_char, sent.end_char, sent.start, sent.end)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43msentence_tokens\u001b[49m\u001b[38;5;241m.\u001b[39mappend([token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sent])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "text = '''This is a 55 y/o M, with H/O Hep C ( presumed from blood transfusions\n",
    "   s/p 3 rd degree burns in an industrial accident in [**2111**]), with known\n",
    "   h/o varices who presented on [**3-26**]^th [**2144**] , with abdominal\n",
    "   distension,jaundice & found to have spontaneous bacterial peritonitis,\n",
    "   was admitted to [**Hospital Ward Name 383**] 10.\n",
    "   Change in mentation noted throughout the day, missed his lactulose dose\n",
    "   [**12-21**] to altered mental status unable to drink safely with risk of\n",
    "   aspiration, creatinine found to be 8.0 ( Baseline 0.8), BUN in 100\n",
    "   HD catheter with VIPort inserted & transferred to MICU 6 for further\n",
    "   management.\n",
    "   Events :\n",
    "   Patient dialyzed from [**2165**] hrs to 2230 hrs with only 500 mls fluid\n",
    "   removal [**12-21**] to Low BP during dialysis.\n",
    "   IV Albumin 100 grams given as per orders.\n",
    "   NGT inserted , had minimal bleeding during insertion. (INR 3.7 in am\n",
    "   lab- had received 4 units of FFP from [**Wardname **]). Had coffee ground NG\n",
    "   aspirate , connected to low intermittent suction until cleared. Due\n",
    "   dose of Lactulose given.\n",
    "   Hepatorenal syndrome\n",
    "   Assessment:\n",
    "   Patient is Anuric since am of [**2145-4-1**] as per report received from [**Hospital Ward Name 383**]\n",
    "   10. Labs drawb prior to Hemodialysis, Please see metavision for lab\n",
    "   values.\n",
    "   Action:\n",
    "   Patient had Hemodialysis done for 2 hours with 500 mls fluid removal\n",
    "   for the first time.\n",
    "   Response:\n",
    "   Renal function continues to be deranged in am labs, continues to be\n",
    "   anuric.\n",
    "   Plan:\n",
    "   Continue monitoring labs, To follow up on next HD\n",
    "   Electrolyte & fluid disorder, other\n",
    "   Assessment:\n",
    "   Action:\n",
    "   Response:\n",
    "   Plan:\n",
    "   Altered mental status (not Delirium)\n",
    "   Assessment:\n",
    "   Action:\n",
    "   Response:\n",
    "   Plan:\n",
    "   Hematemesis (upper GI bleed, UGIB)\n",
    "   Assessment:\n",
    "   Action:\n",
    "   Response:\n",
    "   Plan:\n",
    "   Bradycardia\n",
    "   Assessment:\n",
    "   Action:\n",
    "   Response:\n",
    "   Plan:\n",
    "   Hypotension (not Shock)\n",
    "   Assessment:\n",
    "   Action:\n",
    "   Response:\n",
    "   Plan:\n",
    "'''\n",
    "doc = nlp(text)\n",
    "\n",
    "# for sent in tokens.sents:\n",
    "#     print(sent.text, sent.start_char, sent.end_char, sent.start, sent.end)\n",
    "for sent in doc.sents:\n",
    "    sentence_tokens.append([token.text for token in sent])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The formatt {\"text\": \"Directed by Andrei Zagdansky Not rated ; 72 minutes In the documentary '' Orange Winter '' orange blooms throughout Kiev , Ukraine , the epicenter of dissent over that country 's stolen 2004 presidential elections .\", \"relation\": \"/location/country/capital\", \"h\": {\"id\": \"m.07t21\", \"name\": \"Ukraine\", \"pos\": [123, 130]}, \"t\": {\"id\": \"m.02sn34\", \"name\": \"Kiev\", \"pos\": [116, 120]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify concepts from sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All text are annoated with UMLS CUIs. Go through each sentence and find CUIs in each sentence. If a pair of CUIs have a relation defined in UMLS, label it as a positive sample.\n",
    "\n",
    "Cannot go through local json outputs, since json files with the same ids may not contain the same set of documents. Need to load all the data to search, which is too big. \n",
    "\n",
    "Medcat does not provide sentence split cutoff in the results. So cannot get sentence infor in annotations. Scispacy provides such information. \n",
    "\n",
    "So:\n",
    "1. Use sentence_seg.sh split documents into sentences. \n",
    "2. All annotations have been ingested to ES, which allows query, on openstack. \n",
    "3. Go through each sentences resulted from sentence_seg.sh and collect all annotations in the same sentence. \n",
    "4. Obtain positive and negative samples from openstack instead of hpc. \n",
    "\n",
    "\n",
    "The above process is too complicated. So using NLTK to split sentences and input the annotator to get annotations. \n",
    "using *_sentences.sh job scripts. \n",
    "\n",
    "Using NLTK is very slow and the outputs from NLTK sentence splitters are different from those from spacy. Finally, rewrite the parser for Medcat output and use the \"sentence\" object in the scispacy output to produce sentence-level annotations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate all combinations of entity pairs in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = json.load(open('data/rel_map.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C0000039-C0043950', {'rela': 'mapped_to', 'dir': 'N', 'rui': 'R148171650'}),\n",
       " ('C0000039-C0381030', {'rela': 'mapped_to', 'dir': 'N', 'rui': 'R148166148'}),\n",
       " ('C0000039-C0615231', {'rela': 'mapped_to', 'dir': 'N', 'rui': 'R148263106'})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rels.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine semantic relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of semantic types\n",
    "\n",
    "https://uts.nlm.nih.gov/uts/umls/semantic-network/T187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stypes = pd.read_csv('data/semantic_types_definitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>UI</th>\n",
       "      <th>STY_RL</th>\n",
       "      <th>STN_RTN</th>\n",
       "      <th>DEF</th>\n",
       "      <th>EX</th>\n",
       "      <th>UN</th>\n",
       "      <th>NH</th>\n",
       "      <th>ABR</th>\n",
       "      <th>RIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STY</td>\n",
       "      <td>T001</td>\n",
       "      <td>Organism</td>\n",
       "      <td>A1.1</td>\n",
       "      <td>Generally, a living individual, including all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>orgm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STY</td>\n",
       "      <td>T002</td>\n",
       "      <td>Plant</td>\n",
       "      <td>A1.1.3.3</td>\n",
       "      <td>An organism having cellulose cell walls, growi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>plnt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STY</td>\n",
       "      <td>T004</td>\n",
       "      <td>Fungus</td>\n",
       "      <td>A1.1.3.2</td>\n",
       "      <td>A eukaryotic organism characterized by the abs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fngs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STY</td>\n",
       "      <td>T005</td>\n",
       "      <td>Virus</td>\n",
       "      <td>A1.1.4</td>\n",
       "      <td>An organism consisting of a core of a single n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>virs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STY</td>\n",
       "      <td>T007</td>\n",
       "      <td>Bacterium</td>\n",
       "      <td>A1.1.2</td>\n",
       "      <td>A small, typically one-celled, prokaryotic mic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bact</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RT    UI     STY_RL   STN_RTN  \\\n",
       "0  STY  T001   Organism      A1.1   \n",
       "1  STY  T002      Plant  A1.1.3.3   \n",
       "2  STY  T004     Fungus  A1.1.3.2   \n",
       "3  STY  T005      Virus    A1.1.4   \n",
       "4  STY  T007  Bacterium    A1.1.2   \n",
       "\n",
       "                                                 DEF  EX   UN   NH   ABR  RIN  \n",
       "0  Generally, a living individual, including all ... NaN  NaN  NaN  orgm  NaN  \n",
       "1  An organism having cellulose cell walls, growi... NaN  NaN  NaN  plnt  NaN  \n",
       "2  A eukaryotic organism characterized by the abs... NaN  NaN  NaN  fngs  NaN  \n",
       "3  An organism consisting of a core of a single n... NaN  NaN  NaN  virs  NaN  \n",
       "4  A small, typically one-celled, prokaryotic mic... NaN  NaN  NaN  bact  NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations used in SemRep -- NOT USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data/semRep-ontology.txt') as fo:\n",
    "    for line in fo.readlines():\n",
    "        if line.startswith('UMLS'):\n",
    "            data.append(line.strip().split('|')[-1].split('-'))\n",
    "ont = pd.DataFrame(data, columns=['STY1', 'RL', 'STY2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr2tui = name2tui = pd.Series(stypes.UI.values,index=stypes.ABR).to_dict()\n",
    "ont['STY1_TUI'] = ont['STY1'].map(abr2tui)\n",
    "ont['STY2_TUI'] = ont['STY2'].map(abr2tui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STY1</th>\n",
       "      <th>RL</th>\n",
       "      <th>STY2</th>\n",
       "      <th>STY1_TUI</th>\n",
       "      <th>STY2_TUI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>neop</td>\n",
       "      <td>affects</td>\n",
       "      <td>neop</td>\n",
       "      <td>T191</td>\n",
       "      <td>T191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>drdd</td>\n",
       "      <td>treats</td>\n",
       "      <td>neop</td>\n",
       "      <td>T203</td>\n",
       "      <td>T191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>patf</td>\n",
       "      <td>process_of</td>\n",
       "      <td>fish</td>\n",
       "      <td>T046</td>\n",
       "      <td>T013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>rcpt</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>chvs</td>\n",
       "      <td>T192</td>\n",
       "      <td>T104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>patf</td>\n",
       "      <td>coexists_with</td>\n",
       "      <td>emod</td>\n",
       "      <td>T046</td>\n",
       "      <td>T050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>orgf</td>\n",
       "      <td>process_of</td>\n",
       "      <td>vtbt</td>\n",
       "      <td>T040</td>\n",
       "      <td>T010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>irda</td>\n",
       "      <td>interacts_with</td>\n",
       "      <td>inch</td>\n",
       "      <td>T130</td>\n",
       "      <td>T197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>bpoc</td>\n",
       "      <td>part_of</td>\n",
       "      <td>euka</td>\n",
       "      <td>T023</td>\n",
       "      <td>T204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>patf</td>\n",
       "      <td>affects</td>\n",
       "      <td>npop</td>\n",
       "      <td>T046</td>\n",
       "      <td>T070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>anst</td>\n",
       "      <td>part_of</td>\n",
       "      <td>fish</td>\n",
       "      <td>T017</td>\n",
       "      <td>T013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STY1              RL  STY2 STY1_TUI STY2_TUI\n",
       "466   neop         affects  neop     T191     T191\n",
       "3013  drdd          treats  neop     T203     T191\n",
       "2786  patf      process_of  fish     T046     T013\n",
       "1865  rcpt  interacts_with  chvs     T192     T104\n",
       "1075  patf   coexists_with  emod     T046     T050\n",
       "2771  orgf      process_of  vtbt     T040     T010\n",
       "1785  irda  interacts_with  inch     T130     T197\n",
       "2475  bpoc         part_of  euka     T023     T204\n",
       "583   patf         affects  npop     T046     T070\n",
       "2460  anst         part_of  fish     T017     T013"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ont.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ont['pair'] = ont[['STY1_TUI', 'STY2_TUI']].apply(lambda x : '{}-{}'.format(x[0],x[1]) if str(x[0])<str(x[1]) else '{}-{}'.format(x[1],x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ont[ont['RL']=='treats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read semantic networks --- NOT USEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet = pd.read_csv('data/semantic_networks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(snet['RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2tui = pd.Series(stypes.UI.values,index=stypes.STY_RL).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet['STY1_TUI'] = snet['STY1'].map(name2tui)\n",
    "snet['STY2_TUI'] = snet['STY2'].map(name2tui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2chapter = pd.Series(stypes.STN_RTN.values, index=stypes.UI).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet['pair'] = snet[['STY1_TUI', 'STY2_TUI']].apply(lambda x : '{}-{}'.format(x[0],x[1]) if str(x[0])<str(x[1]) else '{}-{}'.format(x[1],x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(snet[snet['STY1']=='Disease or Syndrome']['RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(snet[snet['STY2']=='Disease or Syndrome']['RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'treats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dup = snet.groupby(['pair'])['RL'].agg(nuni='nunique', uni='unique').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dup['rels'] = rel_dup.uni.apply(lambda x: ', '.join((x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>nuni</th>\n",
       "      <th>uni</th>\n",
       "      <th>rels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>T061-T184</td>\n",
       "      <td>1</td>\n",
       "      <td>[treats]</td>\n",
       "      <td>treats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>T074-T184</td>\n",
       "      <td>1</td>\n",
       "      <td>[treats]</td>\n",
       "      <td>treats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>T121-T184</td>\n",
       "      <td>1</td>\n",
       "      <td>[treats]</td>\n",
       "      <td>treats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>T184-T195</td>\n",
       "      <td>1</td>\n",
       "      <td>[treats]</td>\n",
       "      <td>treats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>T184-T203</td>\n",
       "      <td>1</td>\n",
       "      <td>[treats]</td>\n",
       "      <td>treats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pair  nuni       uni    rels\n",
       "2305  T061-T184     1  [treats]  treats\n",
       "2592  T074-T184     1  [treats]  treats\n",
       "3003  T121-T184     1  [treats]  treats\n",
       "3239  T184-T195     1  [treats]  treats\n",
       "3241  T184-T203     1  [treats]  treats"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_dup[rel_dup['rels']=='treats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STY1</th>\n",
       "      <th>RL</th>\n",
       "      <th>STY2</th>\n",
       "      <th>STY1_TUI</th>\n",
       "      <th>STY2_TUI</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>Medical Device</td>\n",
       "      <td>treats</td>\n",
       "      <td>Sign or Symptom</td>\n",
       "      <td>T074</td>\n",
       "      <td>T184</td>\n",
       "      <td>T074-T184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                STY1      RL             STY2 STY1_TUI STY2_TUI       pair\n",
       "3750  Medical Device  treats  Sign or Symptom     T074     T184  T074-T184"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snet[snet['pair']=='T074-T184']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_dup[rel_dup['uni']==['treats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(i[0] for i in (rel_dup[rel_dup['nuni']==1]['uni']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snet[snet['pair']=='T047-T050']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES:\n",
    "\n",
    "Relations are not totally invertable and a default \"associated_with\" relation is assigned if the relations are not clear.\n",
    "![disease-sign](img/diseas-sign.png)\n",
    "\n",
    "![sign_disease](img/sign_disease.png)\n",
    "\n",
    "![treats-diseases](img/treats-diseases.png)\n",
    "\n",
    "A single relation can be related to multiple different pairs of semtypes, and the same pair of semtypes can have multiple different relations. such as\n",
    "\n",
    "![anti-abnormal](img/anti-abnormal.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The structure of semantic networks: https://uts.nlm.nih.gov/uts/umls/semantic-network\n",
    "\n",
    "(H) \"isa\" and (R) \"associated_with\" are two main categories. That is why every relation isa \"associated_with\". \n",
    "\n",
    "When the relations can be duplicated, how to assign a relation to an pair of concepts. \n",
    "\n",
    "Some pairs have specific relations, while some have more general relations, even if they are from the same semantic types. such as \"treats\", \"prevents\", \"affects\". \n",
    "\n",
    "a) If keep all relations, need to priorize the assignment of relations, from specific to general. Howeve, there is clear \n",
    "\n",
    "b) If remove all general relations, the assumption will be that all relations should be specfic, which will not hold in all cases. \n",
    "\n",
    "The choice of ralations is also dependent on the concept extraction tool, how general or specific the tool can extract. \n",
    "\n",
    "\"REL\" in \"MRREL\" table is not related to the information in Semantic Networks. \"RIN\" in \"SRDEF\" is Inverse of the Relation (RL) https://www.ncbi.nlm.nih.gov/books/NBK9679/table/ch05.T.srdef/\n",
    "\n",
    "Abbrevations of UMLS: https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/abbreviations.html#mrdoc_RELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snet = snet[snet['RL']!='isa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(snet[snet['pair'].isin(rel_overlap[rel_overlap['nuni']==1]['pair'])]['RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(snet['RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rset = stypes[stypes['STY_RL'].str.lower().isin(set(snet['RL']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same pair of types can have different relations, how to choose a relevant one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STY1</th>\n",
       "      <th>RL</th>\n",
       "      <th>STY2</th>\n",
       "      <th>STY1_TUI</th>\n",
       "      <th>STY2_TUI</th>\n",
       "      <th>pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acquired Abnormality</td>\n",
       "      <td>affects</td>\n",
       "      <td>Amphibian</td>\n",
       "      <td>T020</td>\n",
       "      <td>T011</td>\n",
       "      <td>T011-T020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acquired Abnormality</td>\n",
       "      <td>affects</td>\n",
       "      <td>Animal</td>\n",
       "      <td>T020</td>\n",
       "      <td>T008</td>\n",
       "      <td>T008-T020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acquired Abnormality</td>\n",
       "      <td>affects</td>\n",
       "      <td>Archaeon</td>\n",
       "      <td>T020</td>\n",
       "      <td>T194</td>\n",
       "      <td>T020-T194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acquired Abnormality</td>\n",
       "      <td>affects</td>\n",
       "      <td>Bacterium</td>\n",
       "      <td>T020</td>\n",
       "      <td>T007</td>\n",
       "      <td>T007-T020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acquired Abnormality</td>\n",
       "      <td>affects</td>\n",
       "      <td>Bird</td>\n",
       "      <td>T020</td>\n",
       "      <td>T012</td>\n",
       "      <td>T012-T020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   STY1       RL       STY2 STY1_TUI STY2_TUI       pair\n",
       "0  Acquired Abnormality  affects  Amphibian     T020     T011  T011-T020\n",
       "1  Acquired Abnormality  affects     Animal     T020     T008  T008-T020\n",
       "2  Acquired Abnormality  affects   Archaeon     T020     T194  T020-T194\n",
       "3  Acquired Abnormality  affects  Bacterium     T020     T007  T007-T020\n",
       "4  Acquired Abnormality  affects       Bird     T020     T012  T012-T020"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some documents are full of metrics and not provide useful language. So focus on discharge summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes = pd.read_csv('/users/k1810895/data/KER/data/mimic_notes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discharg_dids = set(notes[notes['category']=='Discharge summary']['row_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(discharg_dids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharg_dids = pd.read_csv('data/mimic_discharge_note_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharg_dids = set(discharg_dids['row_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59652"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discharg_dids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Medcat and Scispacy annotation granularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "apath = '/users/k1810895/data/KER/data/scispacy_sentences/'\n",
    "bpath = '/users/k1810895/data/KER/data/medcat_sentence/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_annots(path):\n",
    "    annot_counts = []\n",
    "    annot_types = []\n",
    "    annot_chapters = []\n",
    "    str_len = []\n",
    "    for index in range(1000):\n",
    "        file_name = 'batch' + str(index) + '.json'\n",
    "\n",
    "        docs = json.load(open(path+file_name, 'r'))\n",
    "\n",
    "        for did in docs.keys():\n",
    "            if int(did) in discharg_dids:\n",
    "#             if True:\n",
    "                sents = docs[did]\n",
    "                for sid in sents.keys():\n",
    "                    sent = sents[sid]\n",
    "                    text = sent['sent_text']\n",
    "                    annots = sent['sent_annots']\n",
    "                    annot_counts.append(len(annots))\n",
    "                    for annot in annots:\n",
    "#                       Choose the first semantic type if multiple types are available\n",
    "                        type_str = annot['types'].split(',')[0]\n",
    "#                         annot_types.append(type_str)\n",
    "                        str_len.append(len(annot['text']))\n",
    "                        cha = len(type2chapter[type_str].split('.'))\n",
    "                        annot_chapters.append(cha)\n",
    "    return annot_counts, annot_chapters, str_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_annots_medcat(path):\n",
    "    annot_counts = []\n",
    "    annot_types = []\n",
    "    annot_chapters = []\n",
    "    str_len = []\n",
    "    for index in range(1000):\n",
    "        file_name = 'batch' + str(index) + '.json'\n",
    "\n",
    "        docs = json.load(open(path+file_name, 'r'))\n",
    "\n",
    "        for did in docs.keys():\n",
    "            if int(did) in discharg_dids:\n",
    "#             if True:\n",
    "                sents = docs[did]\n",
    "                for sid in sents.keys():\n",
    "                    sent = sents[sid]\n",
    "                    text = sent['sent_text']\n",
    "                    annots = sent['sent_annots']\n",
    "                    annot_counts.append(len(annots))\n",
    "                    for annot in annots:\n",
    "#                       Choose the first semantic type if multiple types are available\n",
    "                        str_len.append(len(annot['text']))\n",
    "                        type_str = annot['tui'].split(',')[0]\n",
    "                        cha = len(type2chapter[type_str].split('.'))\n",
    "                        annot_chapters.append(cha)\n",
    "    return annot_counts, annot_chapters, str_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_counts, a_chapters, a_str_lens = sentence_annots(apath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_counts, b_chapters, b_str_lens = sentence_annots_medcat(bpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump((a_counts, a_chapters, a_str_lens), open('data/scispacy_annots_stat.pick', 'wb'))\n",
    "# pickle.dump((b_counts, b_chapters, b_str_lens), open('data/medcat_annots_stat.pick', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_counts, a_chapters, a_str_lens = pickle.load(open('data/scispacy_annots_stat.pick', 'rb'))\n",
    "b_counts, b_chapters, b_str_lens = pickle.load(open('data/medcat_annots_stat.pick', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of annotations' chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5322252"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(a_chapters, label='Scispacy', color=\"skyblue\")\n",
    "# sns.histplot(b_chapters, label='MedCAT', color=\"red\")\n",
    "# plt.xlabel(\"Chapter level of entities\")\n",
    "# plt.ylabel(\"PDF (entities)\")\n",
    "# plt.legend()\n",
    "# # plt.title(\"Scispacy on MIMIC\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scispacy 1 272052 0.01225898574119883\n",
      "MedCAT 1 662919 0.021306254178609107\n",
      "Scispacy 2 3501830 0.15779661255238814\n",
      "MedCAT 2 5986285 0.1923995387001957\n",
      "Scispacy 3 9058066 0.4081671957450705\n",
      "MedCAT 3 14643883 0.47065522840620483\n",
      "Scispacy 4 4090146 0.18430682918494048\n",
      "MedCAT 4 4469441 0.1436480866927888\n",
      "Scispacy 5 4481730 0.20195206859682352\n",
      "MedCAT 5 4362863 0.14022266374089304\n",
      "Scispacy 6 784014 0.03532860058702108\n",
      "MedCAT 6 988393 0.03176700695915789\n",
      "Scispacy 7 4210 0.00018970759255747824\n",
      "MedCAT 7 38 1.2213221506506015e-06\n"
     ]
    }
   ],
   "source": [
    "c = Counter(a_chapters)\n",
    "c2 = Counter(b_chapters)\n",
    "for i in range(1, 8):\n",
    "    print('Scispacy', i, c[i], c[i]/len(a_chapters))\n",
    "    print('MedCAT', i, c2[i], c2[i]/len(b_chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scispacy produces more fine grained concepts than Medcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(a_counts)\n",
    "# plt.xlabel(\"Number of entities in a single sentence\")\n",
    "# plt.ylabel(\"PDF (sentences)\")\n",
    "# plt.title(\"Scispacy on MIMIC\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scispacy 1 1017556 0.19118899293006042\n",
      "MedCAT 1 2493600 0.28484658653585837\n",
      "Scispacy 2 1071471 0.20131910326681263\n",
      "MedCAT 2 1771240 0.2023306335963161\n",
      "Scispacy 3 934299 0.17554580279175055\n",
      "MedCAT 3 1282471 0.14649802962834008\n",
      "Scispacy 4 721402 0.1355445025902569\n",
      "MedCAT 4 943554 0.10778317938412549\n",
      "Scispacy 5 504616 0.0948124966649456\n",
      "MedCAT 5 682485 0.07796098917706341\n",
      "Scispacy 6 343141 0.06447289605978823\n",
      "MedCAT 6 473730 0.05411468296424134\n",
      "Scispacy 7 207860 0.039054896310809786\n",
      "MedCAT 7 327024 0.03735630017456792\n"
     ]
    }
   ],
   "source": [
    "c = Counter(a_counts)\n",
    "c2 = Counter(b_counts)\n",
    "for i in range(1, 8):\n",
    "    print('Scispacy', i, c[i], c[i]/len(a_counts))\n",
    "    print('MedCAT', i, c2[i], c2[i]/len(b_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(b_counts)\n",
    "# plt.xlabel(\"Number of entities in a single sentence\")\n",
    "# plt.ylabel(\"PDF (sentences)\")\n",
    "# plt.title(\"Medcat on MIMIC\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=5322252, minmax=(1, 315), mean=4.169672537113988, variance=23.177535766743144, skewness=7.137712520076788, kurtosis=101.30446871524101)\n",
      "DescribeResult(nobs=8754186, minmax=(1, 160), mean=3.5541650588644105, variance=11.60929167019811, skewness=4.334075299061011, kurtosis=44.70064103162898)\n"
     ]
    }
   ],
   "source": [
    "print(stats.describe(a_counts))\n",
    "print(stats.describe(b_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scispacy produces a larger number of annotations than Medcat. A possible reason is that Medcat use the longest string match in choosing concept candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=22192048, minmax=(1, 184), mean=8.970998350400107, variance=32.20667261403639, skewness=1.676493374928002, kurtosis=4.770225798523288)\n",
      "DescribeResult(nobs=31113822, minmax=(3, 70), mean=9.092902761994331, variance=26.84527133431438, skewness=1.6642091664564336, kurtosis=3.9099507773475866)\n"
     ]
    }
   ],
   "source": [
    "print(stats.describe(a_str_lens))\n",
    "print(stats.describe(b_str_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string length in Medcat annotations is longer than scispacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sentences contain too many concepts. Following Mintz's paper, only focus on setences contaning two entities in training data but consider all pairs of entities in test data. The training data will tend to be short sentences. However, the concepts are too details and the RELA are too specific; Use semantic types and semantic relations instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scispacy does not allow to choose a subset of voc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def screen_sentences(path, output_file):\n",
    "    with open(output_file, 'w', buffering=128) as fw:\n",
    "        for index in range(1000):\n",
    "\n",
    "# path = apath\n",
    "# index = 0\n",
    "            file_name = 'batch' + str(index) + '.json'\n",
    "\n",
    "            docs = json.load(open(path+file_name, 'r'))\n",
    "\n",
    "            for did in docs.keys():\n",
    "            #   Only for discharge summary since the quality of the content is relatively higher\n",
    "            #   if int(did) in discharg_dids:\n",
    "                if True:\n",
    "                    sents = docs[did]\n",
    "                    for sid in sents.keys():\n",
    "                        sent = sents[sid]\n",
    "                        text = sent['sent_text']\n",
    "                        doc = nlp(text)\n",
    "                        sentence_tokens = []\n",
    "                        for s in doc.sents:\n",
    "                            for token in s:\n",
    "                                sentence_tokens.append(token.text)\n",
    "\n",
    "\n",
    "                        annots = sent['sent_annots']\n",
    "                        entities = []\n",
    "                        for i, ann in enumerate(annots):\n",
    "                            ann['id'] = i\n",
    "                            span = doc.char_span(ann['start_char'], ann['end_char'])\n",
    "                            ann['start'] = span.start\n",
    "                            ann['end'] = span.end\n",
    "                            entities.append(ann)\n",
    "\n",
    "                        relations = []\n",
    "                        # If include all sentence with any number of annotations. it ends with a super large file\n",
    "                        # Select centain types of annotations to focus. \n",
    "                        for index_ai, ai in enumerate(entities):\n",
    "                            for index_aj, aj in enumerate(entities[index_ai+1:]):\n",
    "                                index_aj = index_aj + index_ai + 1\n",
    "                                ai_cui, aj_cui = ai['cui'], aj['cui']\n",
    "\n",
    "                                min_cui, max_cui = ai_cui, aj_cui\n",
    "                                min_cui_index, max_cui_index = index_ai, index_aj\n",
    "\n",
    "                                if min_cui > max_cui:\n",
    "                                    min_cui, max_cui = aj_cui, ai_cui\n",
    "                                    min_cui_index, max_cui_index = index_aj, index_ai\n",
    "\n",
    "                                cui_key = min_cui + '-' + max_cui                    \n",
    "                                if cui_key in rels:\n",
    "\n",
    "                                    rel = rels[cui_key]['rela']\n",
    "                                    dire = rels[cui_key]['dir']\n",
    "                                    if dire == 'Y':\n",
    "                                        head, tail = min_cui_index, max_cui_index\n",
    "\n",
    "                                    else:\n",
    "                                        head, tail = max_cui_index, min_cui_index\n",
    "            #                         print(cui_key, rels[cui_key])\n",
    "            #                         print({'type': rel,  'head': (entities[head]['cui']), 'tail': entities[tail]['cui']})\n",
    "                                    relations.append({'type': rel,  'head': head, 'tail': tail})\n",
    "                    fw.write(json.dumps({'text': text, 'tokens': sentence_tokens, 'entities': entities, 'relations': relations}))\n",
    "                    fw.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen_sentences(apath, '/users/k1810895/data/KER/data/scispacy_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen_sentences(bpath, '/users/k1810895/data/KER/data/medcat_sentences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 59345 relevant positive sentences from scispacy annotations. and 129748 relevant positive sentences from medcat annotations.  There are few relations in a single sentence. SO USE the whole documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formatt {\"text\": \"Directed by Andrei Zagdansky Not rated ; 72 minutes In the documentary '' Orange Winter '' orange blooms throughout Kiev , Ukraine , the epicenter of dissent over that country 's stolen 2004 presidential elections .\", \"relation\": \"/location/country/capital\", \"h\": {\"id\": \"m.07t21\", \"name\": \"Ukraine\", \"pos\": [123, 130]}, \"t\": {\"id\": \"m.02sn34\", \"name\": \"Kiev\", \"pos\": [116, 120]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule-based method: https://github.com/lhncbc/SemRep \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "A treats B \n",
    "^        ^ \n",
    "|        | \n",
    "c        d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39] *",
   "language": "python",
   "name": "conda-env-.conda-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
